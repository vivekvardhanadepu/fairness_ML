iter:  500.0 , lambda:  1 , alpha:  0.2222222222222222 , kernel: rbf method:  cobyla , catol:  0.0001 batches:  100
x_init:  [6.91592995e-04 2.60751858e-04 9.77434123e-04 ... 5.99560658e-05
 4.10339159e-04 4.07517775e-04]
loss:  438.11634066118063
loss:  468.01465625323686
loss:  467.3598483081408
loss:  469.01698826188806
loss:  464.05491656874733
loss:  466.5350472886244
loss:  470.9877924761801
loss:  471.49549006722253
loss:  451.343244126628
loss:  438.26331129594917
loss:  470.88790499636366
loss:  438.35699231381284
loss:  471.38794834641755
loss:  464.59336798220306
loss:  461.41612161208445
loss:  468.79257060289063
loss:  453.45941300248006
loss:  471.3137786817193
loss:  469.61302702712175
loss:  471.8640316670814
loss:  469.7996461990301
loss:  470.8712097315794
loss:  438.90126505651773
loss:  437.6552998753414
loss:  469.80972054418436
loss:  470.6787079518803
loss:  451.1850015526134
loss:  468.2558780213229
loss:  450.8570592557369
loss:  470.55058663684554
loss:  463.4067631880694
loss:  464.4223182722658
loss:  467.97489292014836
loss:  465.8144741815311
loss:  463.2957792996201
loss:  441.77082557245353
loss:  437.88523180317634
loss:  466.1337305833244
loss:  447.3328348813775
loss:  469.9526193001295
loss:  440.934379999825
loss:  470.36866667412534
loss:  460.70065185481667
loss:  464.5496895151092
loss:  472.1550448826936
loss:  470.4829435635128
loss:  469.0465730661772
loss:  465.5563389997105
loss:  469.07125031768186
loss:  459.60841915034814
loss:  468.701041693754
loss:  470.79806557117803
loss:  468.9438613321004
loss:  469.2272244968904
loss:  455.8957002515779
loss:  447.38594286073123
loss:  438.1971921227779
loss:  468.03909182202966
loss:  470.1330059773214
loss:  471.18945665490827
loss:  456.33750334147277
loss:  439.51233497273495
loss:  437.8301988594853
loss:  468.1302654168361
loss:  468.6607238768128
loss:  450.57220839403936
loss:  437.6490409646687
loss:  469.5233158501169
loss:  469.56550580280856
loss:  469.6483680467362
loss:  467.193361557162
loss:  469.55652272305554
loss:  463.73268865428867
loss:  467.35973706066295
loss:  467.64478351462657
loss:  468.9495626696248
loss:  439.18551840692004
loss:  456.1584763535782
loss:  470.34935732274334
loss:  466.83919921877674
loss:  469.27195255371174
loss:  468.4665984736757
loss:  454.7508594388545
loss:  441.75910295647554
loss:  469.54402138880414
loss:  469.5915222436349
loss:  438.03850970306536
loss:  469.0377860959417
loss:  469.1524023097788
loss:  468.6697393272772
loss:  466.74133387162755
loss:  469.58069940375236
loss:  453.59904282548064
loss:  455.8638442634416
loss:  469.8734043193758
loss:  454.7545139367121
loss:  467.6827111613034
loss:  467.75503469650846
loss:  469.1629823489761
loss:  469.42210174849
loss:  469.54737573234166
loss:  462.90154558384506
loss:  469.3153230537412
loss:  447.6326903566688
loss:  465.291267115356
loss:  469.5909363621192
loss:  459.0891524732991
loss:  469.56891373779484
loss:  469.4776437462413
loss:  470.90266226423455
loss:  466.967133328616
loss:  468.8321491856112
loss:  441.8453380513205
loss:  467.6226523777659
loss:  467.0887626403485
loss:  466.6262053601528
loss:  469.2205446492419
loss:  469.2718395482502
loss:  466.47787661264795
loss:  469.541029878107
loss:  465.3142911792728
loss:  464.5383057586978
loss:  466.52813143693714
loss:  451.39796214584476
loss:  457.2437462405362
loss:  468.8070507908555
loss:  470.8847310238981
loss:  469.5540432575378
loss:  468.11956660255214
loss:  463.97085473600373
loss:  466.44342008242404
loss:  462.3030748234758
loss:  462.60260715714253
loss:  463.94303968124007
loss:  471.12128716393863
loss:  442.6708167778654
loss:  469.5844371036533
loss:  466.58059970331027
loss:  443.05226834979226
loss:  468.42629541195737
loss:  466.99347763996707
loss:  454.33919992590313
loss:  465.7037646114946
loss:  468.8800243027974
loss:  468.9799879023673
loss:  466.3950191936654
loss:  467.0139434563632
loss:  465.6356599218236
loss:  469.6918768749709
loss:  469.26878153453265
loss:  464.78478061814883
loss:  456.3424621254316
loss:  470.63953267030416
loss:  466.89661790771555
loss:  453.75509545618866
loss:  466.3041635470288
loss:  467.96336980327476
loss:  466.9569072901324
loss:  468.29478172855994
loss:  466.93120237880487
loss:  465.66705584656137
loss:  469.24214073656776
loss:  468.99416160805464
loss:  462.60078437758114
loss:  458.99056411310073
loss:  469.4690207331236
loss:  467.86904003478645
loss:  439.7640621381677
loss:  468.8567916408905
loss:  463.94171607957077
loss:  456.3674312164657
loss:  469.97232611279014
loss:  467.83124818779373
loss:  470.0824112177628
loss:  456.0918196528037
loss:  468.86887243292387
loss:  446.10916115325597
loss:  468.2804053503025
loss:  467.6718168059881
loss:  454.904648242279
loss:  468.8369142301128
loss:  459.38171264716726
loss:  465.6618437587652
loss:  466.23295323833537
loss:  459.37849038889834
loss:  469.3969292227202
loss:  467.46872506202766
loss:  468.026340865104
loss:  455.2343941665339
loss:  463.99605212043895
loss:  467.66281026603104
loss:  466.50445990971707
loss:  466.9910985716138
loss:  467.14215380487
loss:  459.774700984609
loss:  451.2206898858022
loss:  468.876548254221
loss:  437.7976462680154
loss:  469.5447693975401
loss:  467.22746399645274
loss:  466.26099825770655
loss:  464.65809484123827
loss:  466.48183639752165
loss:  468.42893626717375
loss:  458.81682106767283
loss:  455.06925146879433
loss:  459.6524156566325
loss:  469.44342392873205
loss:  468.50783115059096
loss:  465.37116046534925
loss:  463.88739512105775
loss:  467.11331636185076
loss:  456.1668533653199
loss:  441.59707348329835
loss:  469.5643865881845
loss:  467.6571556762219
loss:  469.46781053407585
loss:  456.3681551646158
loss:  439.07198238797423
loss:  469.67924907615617
loss:  453.3533712232185
loss:  461.36595076102475
loss:  439.2111927282355
loss:  468.98944971334254
loss:  462.3047783194422
loss:  469.488893393857
loss:  451.6688555222582
loss:  467.9894475880442
loss:  467.46383992841754
loss:  466.995471662563
loss:  469.17144085035494
loss:  469.4708991388384
loss:  467.23170990610765
loss:  454.5688886269224
loss:  466.44786740500797
loss:  467.4331940970078
loss:  467.2239004773127
loss:  442.98007994618865
loss:  448.78891630992354
loss:  465.36978941388986
loss:  465.36821782166135
loss:  470.2108235426361
loss:  469.22442660106645
loss:  468.2404184179173
loss:  461.0980065459078
loss:  460.6609211054169
loss:  468.19115156450874
loss:  462.89842724131285
loss:  470.15626005591446
loss:  466.74646898017147
loss:  469.3987151487876
loss:  470.16314023728694
loss:  471.33786573004386
loss:  465.2733971867128
loss:  453.06688390723394
loss:  471.31360531649545
loss:  458.1887331211287
loss:  460.4253831360529
loss:  468.2817870283632
loss:  451.28879358290317
loss:  468.5929399526021
loss:  468.49260155153036
loss:  456.3188483115588
loss:  470.87691900409266
loss:  469.46501063594116
loss:  469.47672530989627
loss:  451.52784338037316
loss:  437.2852552862752
loss:  468.66165462109575
loss:  439.4111997864357
loss:  467.4113253965651
loss:  468.8045050943992
loss:  469.822752521538
loss:  469.53072106321815
loss:  456.16495966531704
loss:  456.1983379806052
loss:  468.8170404883095
loss:  440.6579729147786
loss:  440.56949598209025
loss:  457.26814129634795
loss:  469.66941294076736
loss:  468.18809814880626
loss:  449.0520247739864
loss:  452.349320902388
loss:  468.51635508956514
loss:  455.8414575693736
loss:  464.84609400045224
loss:  440.53070286588434
loss:  457.36179090097215
loss:  456.23047763323314
loss:  468.7195283855735
loss:  459.6467897963567
loss:  466.6039443642071
loss:  467.379385320812
loss:  466.2697330170355
loss:  466.22482865498154
loss:  437.1345756120948
loss:  466.885164403793
loss:  452.4001327794522
loss:  465.464347884943
loss:  469.0811685850941
loss:  452.86726984327413
loss:  457.91798766438814
loss:  438.0105654104877
loss:  447.20637940413843
loss:  461.63864716176147
loss:  467.1558475822706
loss:  456.05162111989534
loss:  467.51754516676795
loss:  440.466607520695
loss:  467.36249252287377
loss:  467.80492620448683
loss:  453.48604820929296
loss:  467.23304534709604
loss:  467.645792450962
loss:  466.81501756701107
loss:  458.59730736470516
loss:  467.4941286465525
loss:  463.37175856513636
loss:  437.50879337262296
loss:  467.5076768457776
loss:  461.13969202436755
loss:  468.3229023418574
loss:  467.4835170685671
loss:  466.3695488616674
loss:  468.90373014424705
loss:  465.01632517823697
loss:  459.11744553901906
loss:  459.6733330074015
loss:  447.34292984476747
loss:  463.8694362371197
loss:  437.489118782788
loss:  451.80122934796526
loss:  464.1936759336674
loss:  454.3790089661841
loss:  468.9437736043401
loss:  463.61346067476853
loss:  455.53252128232776
loss:  452.99446612816894
loss:  462.2027448462089
loss:  466.79157470116235
loss:  466.9427106593127
loss:  462.95681863338524
loss:  469.29942104976516
loss:  466.5883413756062
loss:  458.72891873401164
loss:  468.64595431643164
loss:  467.78466193991517
loss:  469.27982892305545
loss:  453.2522491085234
loss:  468.31016761516014
loss:  463.26603175758004
loss:  465.9647305494965
loss:  460.28370606654477
loss:  465.4616187459948
loss:  463.8117388412086
loss:  468.50696537366053
loss:  468.46817443493524
loss:  465.0640762728747
loss:  467.75390436248574
loss:  466.4892581979561
loss:  467.9931861560576
loss:  453.4967584513486
loss:  468.11924349520467
loss:  467.97756107951574
loss:  442.4158196668516
loss:  452.9852572281249
loss:  469.5304886166453
loss:  451.43067201741076
loss:  462.8568172428632
loss:  467.797033011766
loss:  467.79082187562
loss:  467.20841393208315
loss:  451.36326687352783
loss:  467.1126929630311
loss:  468.1985496956831
loss:  454.0206868330687
loss:  467.5524100278303
loss:  440.4964696948089
loss:  464.4355779222488
loss:  466.3850589111572
loss:  465.7484986360781
loss:  447.9017192410231
loss:  466.40256502547857
loss:  437.9424204179328
loss:  466.26974008643396
loss:  463.91692525963737
loss:  467.3025679134828
loss:  466.2391060592186
loss:  465.32243502971244
loss:  439.2061399215843
loss:  464.469867441791
loss:  461.2054083218097
loss:  468.90869387451767
loss:  467.8308810257217
loss:  438.49226124091456
loss:  454.510314034191
loss:  465.01638520349064
loss:  467.2794240345187
loss:  466.65531710495395
loss:  465.506767220399
loss:  467.68569312555877
loss:  454.3122341160015
loss:  468.0095032587343
loss:  468.10407932573486
loss:  465.00817730990525
loss:  465.08567312383286
loss:  464.6180648558992
loss:  443.1445396822423
loss:  437.0891700840458
loss:  448.6283462676
loss:  466.9697661071005
loss:  453.2122396331196
loss:  466.9172681409113
loss:  453.4477167362832
loss:  465.07094600110537
loss:  448.16687213596543
loss:  453.5288518823147
loss:  467.24655447082307
loss:  453.09135788337
loss:  463.3013460532407
loss:  467.7446314405961
loss:  465.4542127319344
loss:  457.32651625274303
loss:  448.8921602009296
loss:  459.2867920299659
loss:  468.0333570639849
loss:  468.1775481596565
loss:  463.86209630811
loss:  465.7938568373079
loss:  450.88175655027607
loss:  468.65625012557257
loss:  456.44985540819266
loss:  467.9489314145857
loss:  465.88848264004685
loss:  456.5825357920462
loss:  467.21188495999263
loss:  466.04972925145
loss:  467.2416187948467
loss:  466.66317368673447
loss:  466.4722977659779
loss:  466.8997740059102
loss:  436.88649742124977
loss:  464.5749505542538
loss:  458.60671152570336
loss:  438.25027828874136
loss:  464.1056883415258
loss:  464.2439031232835
loss:  464.28148294016574
loss:  458.37592427782374
loss:  441.5506423246842
loss:  463.4058511478403
loss:  460.39217010651225
loss:  464.92576043975794
loss:  464.524346845113
loss:  440.4846238758808
loss:  462.1230718568783
loss:  466.38757770100557
loss:  456.11788719814746
loss:  448.1656591661678
loss:  455.1213084840821
loss:  456.5032935582077
loss:  441.6569292423528
loss:  459.0842449871426
loss:  463.6561855177478
loss:  457.8777404306946
loss:  452.14765558693296
loss:  441.2815666963914
loss:  465.0480366064627
loss:  462.2967350933784
loss:  463.22517442687837
loss:  463.07388653201417
loss:  463.2506789896628
loss:  464.2433419802031
loss:  464.00549604043135
loss:  465.7376426428143
loss:  461.84204324959296
loss:  453.5631123126504
loss:  461.3324366185577
loss:  464.5368178927677
loss:  436.71597645689064
loss:  456.45963705114707
loss:  463.6990348210073
loss:  461.0974173102719
loss:  463.391006499244
loss:  456.4263072251784
loss:  441.4750560758532
loss:  449.3466971897413
loss:  461.03804617924044
loss:  437.26185034751273
loss:  462.4528305585655
loss:  464.2600326934839
loss:  455.9191535866974
loss:  437.50547191507974
loss:  460.347828138969
loss:  437.40904755036655
loss:  462.3334151668051
loss:  437.6073065193933
loss:  461.8586887196909
loss:  456.2403667348328
weights:  [6.91592995e-04 2.60751858e-04 9.77434123e-04 ... 5.99560658e-05
 4.10339159e-04 4.07517775e-04]
cy dot constraint : -8.814049813201372
Optimization problem did not converge.. Check the solution returned by the optimizer.
Returned solution is:
     fun: 436.71597645689064
   maxcv: 8.814149813201372
 message: 'Did not converge to a solution satisfying the constraints. See `maxcv` for magnitude of violation.'
    nfev: 500
  status: 4
 success: False
       x: array([6.91592995e-04, 2.60751858e-04, 9.77434123e-04, ...,
       5.99560658e-05, 4.10339159e-04, 4.07517775e-04])
Train data:
------------
Train accuracy :  0.7845714285714286
Total data points: 7000
# non-protected examples: 4699
# protected examples: 2301
Non-protected in positive class: 649 (14%)
Protected in positive class: 182 (8%)
P-rule is: 57%

Test data: 
------------
Test accuracy :  0.7813333333333333
Total data points: 3000
# non-protected examples: 2055
# protected examples: 945
Non-protected in positive class: 287 (14%)
Protected in positive class: 86 (9%)
P-rule is: 65%
------------------------------------------------------------------------
------------------------------------------------------------------------
