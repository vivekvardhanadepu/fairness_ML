iter:  600.0 , lambda:  1 , alpha:  0.3333333333333333 , kernel: rbf method:  cobyla , catol:  0.0001 batches:  100
x_init:  [0.00082772 0.00046074 0.00070588 ... 0.00059199 0.00045758 0.0008822 ]
loss:  657.5101932086469
loss:  700.2521961942642
loss:  699.2816706576101
loss:  701.7398239843326
loss:  694.3292726565205
loss:  698.0578830570975
loss:  704.6972723012974
loss:  705.4669942232811
loss:  681.377330094193
loss:  657.9736792028132
loss:  704.526258393234
loss:  658.1770127213084
loss:  705.2731687289102
loss:  695.1014203168933
loss:  690.376547319976
loss:  701.4069765012413
loss:  684.5927560233804
loss:  705.171410879703
loss:  702.6776487861349
loss:  706.0268541271276
loss:  702.9600510477653
loss:  704.5005424129627
loss:  658.8956512490785
loss:  657.0802743288688
loss:  703.1665785962645
loss:  704.4720796924366
loss:  681.3770727046025
loss:  700.8577747777115
loss:  680.8775184035511
loss:  704.2866122201488
loss:  693.5869618273472
loss:  695.1232633137148
loss:  700.3995599042227
loss:  697.2346759854362
loss:  693.4779404929169
loss:  663.1954823766813
loss:  657.7311042963788
loss:  697.7083897672852
loss:  675.5359302723668
loss:  703.3795248398496
loss:  662.0913321448477
loss:  704.0014695102955
loss:  689.5612578855392
loss:  695.2794684348967
loss:  706.7561865116024
loss:  704.4045317824256
loss:  702.0111555795995
loss:  696.800619800911
loss:  702.0471956711649
loss:  687.9271873975014
loss:  701.5190676075846
loss:  704.690112036221
loss:  701.8784782121475
loss:  702.345620156335
loss:  688.5074790574704
loss:  675.611854054084
loss:  658.2379041309108
loss:  700.4964427462642
loss:  703.6492432478128
loss:  705.3031194906183
loss:  683.0689102411209
loss:  660.0227048964326
loss:  657.3204926251608
loss:  700.6450520749772
loss:  701.5133903673799
loss:  680.4387137470383
loss:  657.3776134954845
loss:  704.3421147069026
loss:  704.4032004798097
loss:  704.5250216889931
loss:  700.841989761657
loss:  704.390246384618
loss:  695.6754479356835
loss:  701.0933530716339
loss:  701.5423846745764
loss:  703.5033688201885
loss:  659.52547087841
loss:  688.4066405630064
loss:  705.6466930646885
loss:  700.4403135635288
loss:  703.9608749739565
loss:  702.7479019181233
loss:  686.2861273275349
loss:  663.0588195497277
loss:  704.3675459375014
loss:  704.4402291174088
loss:  658.0176629524606
loss:  703.6191202000332
loss:  703.7810160101822
loss:  703.0634894817777
loss:  700.1941322829621
loss:  704.4228392380224
loss:  684.5283942451713
loss:  687.9692883255534
loss:  704.8808188799118
loss:  686.2918136151901
loss:  701.5985685389079
loss:  701.6801152786003
loss:  703.805902969955
loss:  704.1944092829435
loss:  704.4155122202478
loss:  694.4356056979591
loss:  704.0317240483871
loss:  675.4338070761642
loss:  698.018137132045
loss:  704.4406287659657
loss:  688.7193740414556
loss:  704.427295956095
loss:  704.267820107246
loss:  706.4209194960011
loss:  700.5547514822655
loss:  703.3127661971411
loss:  663.1849389441065
loss:  701.508806222775
loss:  700.7472101468549
loss:  699.9847534932181
loss:  703.8904219983665
loss:  703.9852925059838
loss:  699.80131280336
loss:  704.3630723416254
loss:  698.0508869089826
loss:  696.8924378682229
loss:  699.832610769463
loss:  681.1566823261116
loss:  685.9529455147591
loss:  703.2630029655285
loss:  706.3977245350327
loss:  704.3865102744319
loss:  702.2504279325285
loss:  696.1899788943344
loss:  699.7505937199339
loss:  693.5428979852794
loss:  693.989695259668
loss:  695.9727383641372
loss:  706.7752312519827
loss:  664.4102855005674
loss:  704.431398745892
loss:  700.0663373089122
loss:  664.9729853568444
loss:  702.7070873821016
loss:  700.5703862754025
loss:  685.6592122013584
loss:  698.6467119863487
loss:  703.3833842478629
loss:  703.6177856223605
loss:  699.677072864178
loss:  700.5617573320437
loss:  698.5534762329993
loss:  704.6038844073944
loss:  703.9544010741737
loss:  697.2240200133729
loss:  688.67137947193
loss:  706.025388413267
loss:  700.3919167858315
loss:  684.7850310857251
loss:  699.5206216120514
loss:  702.0475361427118
loss:  700.5279831297869
loss:  702.5115956502718
loss:  700.5440746183443
loss:  698.5916667849261
loss:  703.9229709159571
loss:  703.5432345953051
loss:  693.9868597095083
loss:  688.5691892452314
loss:  704.260345097248
loss:  701.8593984271785
loss:  660.3813598266994
loss:  703.3493127256571
loss:  696.0025175352841
loss:  684.6328656533454
loss:  705.0157957619044
loss:  701.8207291226945
loss:  705.1828430117249
loss:  688.3086941246465
loss:  703.3666067344466
loss:  673.102129373879
loss:  702.4908929743784
loss:  701.5822875534319
loss:  686.5113381630993
loss:  703.3199554754108
loss:  689.155909151215
loss:  698.5838258382906
loss:  699.4134952974215
loss:  689.1509034744935
loss:  704.147477448266
loss:  701.279421911362
loss:  702.111632939836
loss:  687.0148623632919
loss:  696.0681800493612
loss:  701.5690542958399
loss:  699.8410866272668
loss:  700.5668227912815
loss:  700.8479896539455
loss:  689.7475408516209
loss:  680.8751964577095
loss:  703.3796315027595
loss:  657.7384658894058
loss:  704.3714249685735
loss:  700.9193340073958
loss:  699.4780489234163
loss:  697.0492725932493
loss:  699.8069807172362
loss:  702.711100560896
loss:  688.2987097703427
loss:  686.765013929137
loss:  689.5594818426245
loss:  704.2228022971726
loss:  702.8860648410719
loss:  698.1500446905617
loss:  695.9013007580455
loss:  700.7654463461862
loss:  688.4096705889299
loss:  663.9588408623911
loss:  704.4024286521936
loss:  701.5603630922751
loss:  704.2597203382983
loss:  688.6752700795951
loss:  657.9262400521178
loss:  704.5720322540658
loss:  684.1735838938534
loss:  692.1008748953296
loss:  660.0622496978256
loss:  703.5362020826851
loss:  693.5453097498696
loss:  704.284815443768
loss:  681.6106520585403
loss:  702.0387341778251
loss:  701.2538957354159
loss:  700.5733774203409
loss:  703.8098283863931
loss:  704.2578652842336
loss:  700.9257259159218
loss:  681.9466098824836
loss:  699.7572553381431
loss:  701.2273929514724
loss:  700.9142146157498
loss:  664.8673409408555
loss:  677.1917479730844
loss:  698.1479712706619
loss:  698.1456334866119
loss:  705.3829799125245
loss:  703.8962800938025
loss:  702.4869783090351
loss:  691.730573293434
loss:  691.0641807673494
loss:  702.3437036682482
loss:  694.4309999037754
loss:  705.3448488706761
loss:  700.2020469575116
loss:  704.1555895008601
loss:  705.315917601515
loss:  707.1045772872715
loss:  697.9560161712267
loss:  683.7129422200449
loss:  707.0681210999497
loss:  687.3651780863277
loss:  690.7266174474415
loss:  702.4716908676357
loss:  680.9825866728876
loss:  702.9555589282484
loss:  702.809805999264
loss:  688.6330263063466
loss:  706.405194634215
loss:  704.2541145185165
loss:  704.2668411974935
loss:  681.3942860675888
loss:  656.8195189899839
loss:  703.3153509859444
loss:  660.1371987257489
loss:  701.4524847395963
loss:  703.5618698779201
loss:  705.0628652356154
loss:  704.6218610228408
loss:  688.6311124823786
loss:  688.6762663007021
loss:  703.5443116196595
loss:  661.8891809849954
loss:  661.7576210261684
loss:  690.2777261169466
loss:  704.8336157130922
loss:  702.6103394689679
loss:  677.8045117608845
loss:  682.8475083857448
loss:  703.0994746452902
loss:  688.1640674803396
loss:  697.6276825482568
loss:  661.7008220701041
loss:  686.366278337345
loss:  688.693820243514
loss:  703.4018304888807
loss:  689.811742795659
loss:  700.249860472566
loss:  701.3876058418286
loss:  699.7666830606804
loss:  699.6491017296684
loss:  656.8827451586234
loss:  701.6945646184263
loss:  682.8033857486603
loss:  699.5552965835783
loss:  704.983111772748
loss:  683.5541104437199
loss:  688.2200532652477
loss:  658.518347802175
loss:  674.6160907961832
loss:  693.7791161292479
loss:  702.0817365918216
loss:  688.3696842233779
loss:  702.6206279180678
loss:  661.791726415358
loss:  702.3562430820775
loss:  703.025788626587
loss:  684.4736573394431
loss:  702.1957291212715
loss:  702.8111762576731
loss:  701.5730998270454
loss:  689.205741552482
loss:  702.5986953486712
loss:  696.4217335118086
loss:  658.1549583113164
loss:  702.5751646220943
loss:  693.0647109218011
loss:  703.8347872628067
loss:  702.5439321416177
loss:  700.9069628008127
loss:  704.6966277045364
loss:  698.8847417362635
loss:  689.9493921945932
loss:  690.8459652010931
loss:  675.1151514976032
loss:  697.1054624188362
loss:  657.659458143065
loss:  681.8736518322247
loss:  697.6540605309764
loss:  682.9018882758318
loss:  704.7552611612243
loss:  696.7765643233635
loss:  684.5938127039533
loss:  683.7206087081747
loss:  694.6541283538575
loss:  701.5642489072927
loss:  701.7632389672409
loss:  695.7751316190756
loss:  705.2998347932333
loss:  701.2342720034273
loss:  689.4333134909157
loss:  704.3266156953129
loss:  703.0176555752431
loss:  705.2651803925064
loss:  681.2076309419273
loss:  703.835849397632
loss:  696.2651761914177
loss:  700.303038885085
loss:  691.7158011109531
loss:  699.5514780070249
loss:  697.0813511704193
loss:  704.1171916758166
loss:  704.023031053494
loss:  698.9289496335033
loss:  702.9721994907709
loss:  701.0379386951125
loss:  703.3269720648108
loss:  684.5215057420239
loss:  703.5220992255828
loss:  703.3032999218311
loss:  664.4857611094318
loss:  683.706239522117
loss:  705.6301667179068
loss:  681.3743039085431
loss:  695.6516621052036
loss:  703.0139381809471
loss:  703.0276586426369
loss:  702.160044142681
loss:  681.2660658193004
loss:  702.0169181990891
loss:  703.6280423371809
loss:  685.2968502368919
loss:  702.6407241798341
loss:  661.8357183650219
loss:  698.0166807801322
loss:  700.8810357318503
loss:  699.979489566662
loss:  675.9694487781453
loss:  700.9668766019345
loss:  657.8897522528308
loss:  700.7097893279431
loss:  697.1769961232701
loss:  702.2982563308573
loss:  700.7130487330279
loss:  699.289372479706
loss:  660.0326102469952
loss:  698.0674735188069
loss:  693.1507572716148
loss:  704.7294793146169
loss:  703.1005792676717
loss:  659.0279487804792
loss:  686.044922137218
loss:  698.8848449248928
loss:  702.2653680861199
loss:  701.2944411328575
loss:  699.6089504715172
loss:  702.8711101868109
loss:  685.7409280392293
loss:  703.3298111229044
loss:  703.4827380218449
loss:  698.8727254935417
loss:  698.9223379162654
loss:  698.2641856448128
loss:  668.5003249002389
loss:  657.0729731985573
loss:  676.6797864100503
loss:  703.1339369626099
loss:  683.7068353156627
loss:  703.0112227507251
loss:  684.0208143000906
loss:  700.3000966985544
loss:  675.9762958178349
loss:  684.144180012793
loss:  703.5277232203102
loss:  683.5218691477617
loss:  697.6422178149043
loss:  704.250908244888
loss:  700.8719857027701
loss:  688.6380476166383
loss:  677.0786927825142
loss:  691.5941225515585
loss:  704.7202364015116
loss:  704.9477043130217
loss:  698.4851499661739
loss:  701.3198999018799
loss:  680.1360644543175
loss:  705.6556968143626
loss:  688.5680976162785
loss:  704.607482458971
loss:  701.5245229186157
loss:  688.7710076489024
loss:  703.4720836258034
loss:  701.7655999591632
loss:  703.5344679169366
loss:  702.6171225863839
loss:  702.3257539974976
loss:  703.0238717793741
loss:  657.0627023105901
loss:  703.6066597031659
loss:  690.0341004045072
loss:  657.6375797952819
loss:  702.4268359293471
loss:  703.165071157393
loss:  703.2175901738461
loss:  694.0015069463487
loss:  664.6336753045466
loss:  701.8574470442076
loss:  697.3136439099399
loss:  704.034806256072
loss:  703.5540172950457
loss:  661.8961602799523
loss:  699.987124469384
loss:  706.1779713971237
loss:  686.3407212969647
loss:  674.0429136295502
loss:  689.384498919222
loss:  686.959686971694
loss:  664.7976502995265
loss:  695.4047626975155
loss:  702.2771343214307
loss:  693.3079315233248
loss:  684.4160951009532
loss:  664.4960498146804
loss:  704.3479020082657
loss:  700.2493845193891
loss:  701.6019649550702
loss:  701.3958306289489
loss:  701.6641452681204
loss:  703.1641653531746
loss:  702.6525944366704
loss:  705.3254426227504
loss:  699.5603766285903
loss:  682.4782144120095
loss:  698.6040531461498
loss:  703.567563862312
loss:  656.7845851846853
loss:  691.6739951954942
loss:  702.5610171611407
loss:  698.6766394666289
loss:  702.1165135313433
loss:  686.8937002253743
loss:  664.733472396972
loss:  676.0451453615027
loss:  698.6036044882837
loss:  657.688500451438
loss:  700.6986351464255
loss:  703.4052788415122
loss:  686.1310517233492
loss:  658.0563451791935
loss:  697.5408400635865
loss:  658.2743525868963
loss:  700.5450143030516
loss:  657.2257037036491
loss:  699.8332859868653
loss:  686.5826334919756
loss:  696.1965750206689
loss:  702.4233459617901
loss:  703.5449122283551
loss:  657.2247814980143
loss:  700.0590646505256
loss:  699.3093418514375
loss:  703.6106927301951
loss:  698.9569166524661
loss:  697.8583037388252
loss:  684.4820327984677
loss:  657.6934666738173
loss:  669.2332548390073
loss:  698.2468855461393
loss:  662.5242344740785
loss:  661.8508707557166
loss:  700.636168128517
loss:  664.4237853030917
loss:  698.2979665317905
loss:  691.0080445933975
loss:  660.0842623915269
loss:  693.3572444815662
loss:  657.5161159377608
loss:  703.5064938162313
loss:  682.9483473466123
loss:  690.2309808901069
loss:  702.4818029458277
loss:  694.1212508416124
loss:  685.2778333054565
loss:  685.1082282508232
loss:  700.5388576629495
loss:  697.9188043054526
loss:  702.5929528504436
loss:  701.9602004223159
loss:  682.1003173604668
loss:  701.7399955098442
loss:  697.1118485359709
loss:  699.3569165931832
loss:  688.512159647652
loss:  698.6153879248793
loss:  699.0087855760992
loss:  700.2664430438912
loss:  699.3507893764075
loss:  701.2679623911214
loss:  702.1991316883898
loss:  705.3279181941261
loss:  676.2505314214859
loss:  657.5611980186268
loss:  664.5998037104897
loss:  703.8968170353747
loss:  700.615021033659
loss:  698.311010799881
loss:  658.2484707715525
loss:  698.6800958214636
loss:  661.8153157182633
loss:  676.0446302518519
loss:  693.4462647058012
loss:  686.881791647013
loss:  701.0123375963165
loss:  702.4399946093245
loss:  672.4967946603954
loss:  687.3891994952935
loss:  697.8671064782848
loss:  679.4756310167302
loss:  684.2485107276118
loss:  701.3014342286032
loss:  689.271346000077
loss:  699.3998544968518
loss:  699.6154306591945
loss:  701.2732111047997
loss:  700.2578167967208
loss:  702.5397261343703
loss:  700.5457302077837
loss:  656.0632646721205
loss:  658.8826561260411
loss:  699.3926732107848
loss:  696.980296361152
loss:  698.2430100272986
loss:  682.0356451714025
loss:  703.2091067874657
loss:  702.952623119745
loss:  697.3237015574146
loss:  700.9925348262769
loss:  690.8395028277682
loss:  683.6830811530883
loss:  681.6132566172255
loss:  696.686345535293
loss:  699.1281895854444
loss:  655.5497535667932
loss:  693.2985285985993
loss:  698.9456218906283
loss:  680.0227171064139
loss:  671.6067690872836
loss:  690.5277929158041
loss:  674.181080092235
loss:  660.6161367021308
loss:  684.1022521963285
loss:  655.4564683318664
loss:  700.9665211896707
loss:  680.6130807674369
loss:  658.4828610384268
weights:  [0.00082772 0.00046074 0.00070588 ... 0.00059199 0.00045758 0.0008822 ]
cy dot constraint : -5.7688793187095975
Optimization problem did not converge.. Check the solution returned by the optimizer.
Returned solution is:
     fun: 655.4564683318664
   maxcv: 5.768979318709597
 message: 'Did not converge to a solution satisfying the constraints. See `maxcv` for magnitude of violation.'
    nfev: 600
  status: 4
 success: False
       x: array([0.00082772, 0.00046074, 0.00070588, ..., 0.00059199, 0.00045758,
       0.0008822 ])
Train data:
------------
Train accuracy :  0.7804285714285715
Total data points: 7000
# non-protected examples: 4699
# protected examples: 2301
Non-protected in positive class: 676 (14%)
Protected in positive class: 194 (8%)
P-rule is: 59%

Test data: 
------------
Test accuracy :  0.7766666666666666
Total data points: 3000
# non-protected examples: 2055
# protected examples: 945
Non-protected in positive class: 298 (15%)
Protected in positive class: 93 (10%)
P-rule is: 68%
------------------------------------------------------------------------
------------------------------------------------------------------------
