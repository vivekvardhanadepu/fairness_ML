iter:  400.0 , lambda:  1 , alpha:  0.0 , kernel: rbf method:  cobyla , catol:  0.0001 batches:  100
x_init:  [9.50448164e-05 3.43538421e-04 2.41009645e-05 ... 7.66770783e-04
 5.61257110e-04 2.36288463e-04]
loss:  -1.8296822009593778
loss:  -0.5013389723528388
loss:  -0.5125792958803972
loss:  -0.48858236836831903
loss:  -0.5325551878776631
loss:  -0.5250271542501226
loss:  -0.5660658192706554
loss:  -0.5006482278217659
loss:  -4.06906610682357
loss:  -4.566289599846351
loss:  -4.178834330601832
loss:  -5.068110630714864
loss:  -4.721117188083905
loss:  -4.634354582205379
loss:  -4.626009098915416
loss:  -4.625846123279572
loss:  -6.363011924484705
loss:  -7.056555993513737
loss:  -6.870205476918178
loss:  -6.660640393068139
loss:  -6.622756790747225
loss:  -6.662243794034849
loss:  -7.548726579782608
loss:  -8.04500753438921
loss:  -7.634773473513176
loss:  -7.7234187125293285
loss:  -9.29326781634381
loss:  -9.75796567421343
loss:  -10.898840372677393
loss:  -11.653210312346541
loss:  -11.07083137480397
loss:  -11.491195099892751
loss:  -11.246717513130596
loss:  -11.0010773043576
loss:  -11.624708187926064
loss:  -12.134771521845712
loss:  -11.749574312436614
loss:  -11.491158369285827
loss:  -13.300356257312286
loss:  -13.770639224265883
loss:  -14.23312061729155
loss:  -13.774461401114047
loss:  -13.463114381429236
loss:  -13.746994673164872
loss:  -14.068229065058265
loss:  -14.302091000747017
loss:  -12.95809852791476
loss:  -12.851012564362183
loss:  -12.956921849588419
loss:  -12.940287139460473
loss:  -12.848192138756266
loss:  -12.878831091514632
loss:  -12.853200889520451
loss:  -13.367064925685195
loss:  -16.578551416979387
loss:  -17.608638874776496
loss:  -18.10407848757768
loss:  -18.756407526988625
loss:  -18.330190868057805
loss:  -18.28670655598362
loss:  -18.142497177771013
loss:  -19.23041542180855
loss:  -19.205643184079527
loss:  -19.051001287484258
loss:  -19.354742110358902
loss:  -21.61361225258394
loss:  -22.10384087898844
loss:  -21.817154582552725
loss:  -21.821005052901665
loss:  -21.894296791568703
loss:  -21.713804932160063
loss:  -21.840727374630433
loss:  -21.546109367095337
loss:  -22.10845823682589
loss:  -20.773988808202613
loss:  -20.806446754977475
loss:  -23.149144224556036
loss:  -25.447659710449884
loss:  -25.44754878192824
loss:  -25.354461189371268
loss:  -25.29824459336125
loss:  -25.21354773967068
loss:  -26.66826861604565
loss:  -26.155472693973344
loss:  -27.47811942180943
loss:  -27.254368694898947
loss:  -27.98048663583441
loss:  -27.912947756493097
loss:  -27.733046107031146
loss:  -27.69828946061081
loss:  -27.63288439812701
loss:  -27.782515858794326
loss:  -29.16642868042225
loss:  -29.449912431175015
loss:  -31.308806523069002
loss:  -31.503695360239007
loss:  -33.19273462121247
loss:  -34.10261783116766
loss:  -33.92543220245855
loss:  -33.92511493718274
loss:  -33.9432520903697
loss:  -33.82990765404061
loss:  -33.9266474696118
loss:  -35.140072875458
loss:  -35.74035954910512
loss:  -35.59932837963096
loss:  -35.24463376753314
loss:  -35.546383956271484
loss:  -35.695328742902504
loss:  -35.68734754409763
loss:  -35.42950654402068
loss:  -35.51937784209646
loss:  -35.228782023926385
loss:  -35.42716825258784
loss:  -35.451413605774086
loss:  -35.748788331395794
loss:  -34.603022872128115
loss:  -34.643420895455534
loss:  -34.536085493963576
loss:  -34.69498101243974
loss:  -34.51881911275289
loss:  -34.49978729401123
loss:  -34.61027301653999
loss:  -37.74696765605258
loss:  -37.26297433553254
loss:  -37.68632236016108
loss:  -37.77427182321548
loss:  -36.66342735777475
loss:  -36.61886649235249
loss:  -37.47886933352367
loss:  -36.63297036562575
loss:  -36.5566415188849
loss:  -36.552424508550565
loss:  -36.50209267055921
loss:  -36.92940336358395
loss:  -37.68923231896156
loss:  -36.656050567177694
loss:  -37.37403043276494
loss:  -37.66849505552699
loss:  -36.615290477232065
loss:  -36.6148437157724
loss:  -39.87871409074695
loss:  -39.65926880400835
loss:  -39.708321779437554
loss:  -40.01891786654412
loss:  -38.89296370404992
loss:  -39.047904366223094
loss:  -38.91004838182033
loss:  -39.003965332105
loss:  -39.092322488175384
loss:  -38.94544251699538
loss:  -42.08773518530328
loss:  -42.08226150335227
loss:  -42.00623008371222
loss:  -43.08429044438596
loss:  -44.126401910921516
loss:  -44.2310102206337
loss:  -43.2994928586221
loss:  -43.29479662109093
loss:  -43.67133935590199
loss:  -43.287792101890915
loss:  -43.30581874009313
loss:  -43.395962282937724
loss:  -43.272578949651255
loss:  -43.2794601882203
loss:  -43.320335897941206
loss:  -43.29006811937263
loss:  -44.7069098476042
loss:  -43.785766250405985
loss:  -43.7555752571095
loss:  -43.793583134537926
loss:  -43.80981337417241
loss:  -43.77943135815954
loss:  -43.8667836957262
loss:  -46.62629129238512
loss:  -46.68794562286253
loss:  -48.43325552767515
loss:  -48.43382098330337
loss:  -47.404454278750165
loss:  -50.34041545351183
loss:  -50.353103235791956
loss:  -49.18590030124828
loss:  -49.25848734089419
loss:  -49.70227872747449
loss:  -49.18026950241041
loss:  -49.46082311136253
loss:  -49.2889376444647
loss:  -49.328500917048416
loss:  -52.267386812771264
loss:  -52.08212091789768
loss:  -52.19856758418583
loss:  -52.13796752617946
loss:  -52.162083192473894
loss:  -52.239717193428866
loss:  -51.99349227185443
loss:  -53.078047069048125
loss:  -54.03914158419471
loss:  -55.02771920004688
loss:  -55.14921100900448
loss:  -54.00950479454532
loss:  -53.980152811859114
loss:  -54.56811052188791
loss:  -53.984001217830134
loss:  -54.06774736041329
loss:  -53.92466020475181
loss:  -57.07098743749835
loss:  -56.72259660349405
loss:  -57.083333351344066
loss:  -56.08488133967573
loss:  -55.874574367074
loss:  -55.89396645076854
loss:  -55.96089446385216
loss:  -59.1134340789759
loss:  -60.59527220624
loss:  -60.624442064217135
loss:  -59.51354685459921
loss:  -59.66839823473946
loss:  -62.71884224753302
loss:  -62.74064320764782
loss:  -62.781116586457394
loss:  -64.72420152963703
loss:  -64.78620430734186
loss:  -65.2551458304443
loss:  -64.43832147636006
loss:  -64.23795458510646
loss:  -64.40695963971676
loss:  -66.96370461637898
loss:  -66.96930240206348
loss:  -66.2306416715526
loss:  -66.00603978156234
loss:  -66.08156123558564
loss:  -66.1416135446422
loss:  -66.00902755636561
loss:  -65.7516166900158
loss:  -66.03400552914592
loss:  -66.04809932912183
loss:  -66.01752299888004
loss:  -67.52474217447855
loss:  -69.08211233412264
loss:  -69.034267382611
loss:  -69.0339056094734
loss:  -69.22281096273034
loss:  -68.26494297658411
loss:  -68.58907517289032
loss:  -68.02045954967463
loss:  -67.99421814514648
loss:  -68.46159770042249
loss:  -68.0822659822295
loss:  -68.62293752499724
loss:  -68.23367983436853
loss:  -68.27435016288597
loss:  -68.60630013203239
loss:  -68.67354378134384
loss:  -68.05069353087163
loss:  -71.09979544794388
loss:  -71.48709905098622
loss:  -70.27152599890192
loss:  -70.29378891058083
loss:  -70.48216121472566
loss:  -73.16550048332235
loss:  -73.17122001283333
loss:  -72.19300128382385
loss:  -75.11817650244558
loss:  -75.36874956087499
loss:  -74.43725979716562
loss:  -74.52414514539527
loss:  -77.06315521660048
loss:  -77.55926865749763
loss:  -77.61325500881568
loss:  -77.09466199819123
loss:  -76.58765726164019
loss:  -76.7756400075431
loss:  -76.82405670331352
loss:  -76.76594632542196
loss:  -79.55107352012217
loss:  -80.49316954065469
loss:  -81.55369969347767
loss:  -81.01760690298428
loss:  -81.05263321141803
loss:  -82.54081177909367
loss:  -83.64200802731405
loss:  -83.65933422574449
loss:  -85.23844242419227
loss:  -86.25313178474283
loss:  -87.23092740922698
loss:  -88.24587574219102
loss:  -89.19720381283256
loss:  -88.67801038541035
loss:  -88.8321092216675
loss:  -90.23472946880588
loss:  -91.28497860709291
loss:  -90.96313463921106
loss:  -91.31078426202312
loss:  -90.22706920951262
loss:  -90.4146335841003
loss:  -90.17660779735345
loss:  -91.69083089628752
loss:  -91.42184406446773
loss:  -93.56268427122579
loss:  -93.5037983829508
loss:  -93.83323412974424
loss:  -95.6623341454627
loss:  -95.25421152685162
loss:  -96.15028411809293
loss:  -97.05320805545065
loss:  -97.60144646853098
loss:  -97.44410123186326
loss:  -98.67316584125652
loss:  -99.57216538499942
loss:  -99.03966691413255
loss:  -99.73738296687917
loss:  -98.85510369470033
loss:  -101.5966202268045
loss:  -101.44149932411952
loss:  -101.50517623781695
loss:  -101.4462806424733
loss:  -101.06940491229295
loss:  -101.5746543258654
loss:  -101.19864780607708
loss:  -102.93323839532754
loss:  -103.06520595144171
loss:  -101.76628192017904
loss:  -102.10581843843367
loss:  -102.25943805147999
loss:  -101.92603757227107
loss:  -102.16796883405644
loss:  -101.92213193041525
loss:  -101.96247954649219
loss:  -101.7084375940913
loss:  -104.59221351113574
loss:  -104.34148485644168
loss:  -105.0135206769724
loss:  -105.84229029491027
loss:  -106.4525942306076
loss:  -105.49973857004348
loss:  -106.57501990266098
loss:  -105.18627392362305
loss:  -105.02600729790227
loss:  -108.40772934802632
loss:  -107.77135464029544
loss:  -108.43975688342105
loss:  -107.26814014828855
loss:  -108.61821335587271
loss:  -107.08059265191153
loss:  -106.7104031930161
loss:  -106.50803743363389
loss:  -106.88624323782072
loss:  -106.96421214745132
loss:  -107.05090820584444
loss:  -106.4494001462932
loss:  -106.95678664406259
loss:  -106.4944831540143
loss:  -106.69680619149457
loss:  -107.16968894331347
loss:  -106.72769528614538
loss:  -106.48780648600683
loss:  -106.8644850764538
loss:  -107.35941703131292
loss:  -106.76850078009394
loss:  -106.88886472086205
loss:  -107.41630211453423
loss:  -106.9509628251974
loss:  -111.16795634687952
loss:  -110.43584529984797
loss:  -110.4825500305024
loss:  -110.71046979648753
loss:  -112.58550310930006
loss:  -113.21567036380442
loss:  -114.61198465506834
loss:  -114.25284510144402
loss:  -115.21823244992689
loss:  -114.5103397019306
loss:  -114.4601871316277
loss:  -116.56057532011708
loss:  -116.68342710198758
loss:  -116.15109251220022
loss:  -118.16582023075027
loss:  -119.19293838600836
loss:  -118.67598163712289
loss:  -118.24998713632179
loss:  -119.04340341933535
loss:  -118.26810904023696
loss:  -120.53002336882736
loss:  -120.59630544658303
loss:  -120.86680749464628
loss:  -120.65032732077206
loss:  -120.39341062715567
loss:  -120.01291557820119
loss:  -119.93424273446757
loss:  -120.44353313855366
loss:  -120.35988652701617
loss:  -119.78576204838477
loss:  -119.68732284027766
loss:  -120.3179989724234
loss:  -120.0725939514583
loss:  -121.34936385838685
loss:  -122.92681356845908
loss:  -122.84549691162698
loss:  -123.08938929473075
loss:  -122.74181743303355
weights:  [9.50448164e-05 3.43538421e-04 2.41009645e-05 ... 7.66770783e-04
 5.61257110e-04 2.36288463e-04]
cy dot constraint : -5.850405637404773
Optimization problem did not converge.. Check the solution returned by the optimizer.
Returned solution is:
     fun: -123.08938929473075
   maxcv: 5.850505637404773
 message: 'Did not converge to a solution satisfying the constraints. See `maxcv` for magnitude of violation.'
    nfev: 400
  status: 4
 success: False
       x: array([9.50448164e-05, 3.43538421e-04, 2.41009645e-05, ...,
       7.66770783e-04, 5.61257110e-04, 2.36288463e-04])
Train data:
------------
Train accuracy :  0.7832857142857143
Total data points: 7000
# non-protected examples: 4699
# protected examples: 2301
Non-protected in positive class: 778 (17%)
Protected in positive class: 222 (10%)
P-rule is: 58%

Test data: 
------------
Test accuracy :  0.7753333333333333
Total data points: 3000
# non-protected examples: 2055
# protected examples: 945
Non-protected in positive class: 341 (17%)
Protected in positive class: 102 (11%)
P-rule is: 65%
------------------------------------------------------------------------
------------------------------------------------------------------------
