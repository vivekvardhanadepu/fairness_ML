{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "consecutive-lodge",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils as ut\n",
    "import loss_funcs as lf\n",
    "import numpy as np\n",
    "from prep_adult_data import *\n",
    "from contextlib import redirect_stdout\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dated-layout",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for file 'adult.data' in the current directory...\n",
      "File found in current directory..\n",
      "Looking for file 'adult.test' in the current directory...\n",
      "File found in current directory..\n",
      "Loading only 10000 examples from the data\n",
      "Total data points: 10000\n",
      "# non-protected examples: 6754\n",
      "# protected examples: 3246\n",
      "Non-protected in positive class: 2080 (31%)\n",
      "Protected in positive class: 372 (11%)\n",
      "P-rule is: 37%\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Load the adult data \"\"\"\n",
    "X, y, x_control = load_adult_data(load_data_size=10000) # set the argument to none, or no arguments if you want to test with the whole data -- we are subsampling for performance speedup\n",
    "ut.compute_p_rule(x_control[\"sex\"], y) # compute the p-rule in the original data\n",
    "\n",
    "\n",
    "\n",
    "\"\"\" Split the data into train and test \"\"\"\n",
    "train_fold_size = 0.7\n",
    "x_train, y_train, x_control_train, x_test, y_test, x_control_test = ut.split_into_train_test(X, y, x_control, train_fold_size)\n",
    "\n",
    "loss_function = lf.discrepancy_loss\n",
    "sensitive_attrs = [\"sex\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incident-montreal",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(10):\n",
    "#     for i in range(x_train.shape[0]):\n",
    "#         kernel_values.append(np.squeeze(ut.rbf_kernel(x_train[i], x_train)))\n",
    "    n = x_train.shape[0]\n",
    "    kernel_matrix = np.zeros((n, n))\n",
    "    rbf_kernel = ut.rbf_kernel(1/n)\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            kernel_matrix[i, j] = rbf_kernel(x_train[i], x_train[j])\n",
    "#     kernel_values  = np.array(kernel_matrix)\n",
    "    svm_loss = .5*np.dot((y_train*y_train).T @ kernel_matrix, y_train*y_train)\n",
    "    svm_loss -= y_train.sum()\n",
    "    print(svm_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "needed-concrete",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_classifier():\n",
    "    \n",
    "#     final_c, Cs, losses = ut.train_model(x_train, y_train, x_control_train, loss_function,sensitive_attrs, max_iter, alpha, l, method, initiator, catol)\n",
    "    final_c, Cs, losses = ut.train_model(x_train, y_train, x_control_train, loss_function, sensitive_attrs, max_iter, \n",
    "                                            alpha, l, method, initiator, catol)\n",
    "    y_train_predicted, y_test_predicted = ut.predict(final_c.x, x_train, y_train, x_test)\n",
    "    train_score, test_score, correct_answers_train, correct_answers_test = \\\n",
    "                                            ut.check_accuracy(None, x_train, y_train, \n",
    "                                                              x_test, y_test, y_train_predicted, y_test_predicted)\n",
    "    print(\"Train data:\")\n",
    "    print(\"------------\")\n",
    "    print(\"Train accuracy : \", train_score)\n",
    "    p_rule_train = ut.compute_p_rule(x_control_train[\"sex\"], y_train_predicted)\n",
    "    print()\n",
    "    print(\"Test data: \")\n",
    "    print(\"------------\")\n",
    "    print(\"Test accuracy : \", test_score)\n",
    "    p_rule_test = ut.compute_p_rule(x_control_test[\"sex\"], y_test_predicted)\n",
    "    print(\"------------------------------------------------------------------------\")\n",
    "    print(\"------------------------------------------------------------------------\")\n",
    "    print\n",
    "    print\n",
    "    return Cs, losses, train_score, test_score, p_rule_train, p_rule_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "polished-orbit",
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'cobyla'\n",
    "# l_list = np.linspace(start= 0.00000001, stop= 10, num= 5)     # lamda list\n",
    "alpha_list = np.linspace(start=0.0 , stop= 1.0, num= 10)\n",
    "# initiator_list = np.linspace(start= 0, stop= 0.01, num= 10) # for initial values of c\n",
    "max_iter_list = np.linspace(start= 100, stop= 1000, num= 10) # no of iterations\n",
    "# catol_list = np.linspace(start=0, stop= 0.01, num= 5)\n",
    "initiator = 0.001\n",
    "l = 1\n",
    "catol = 0.0001\n",
    "alpha = 0.5\n",
    "max_iter = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "heard-catering",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "result = {'l':[], 'alpha':[], 'initiator':[], 'max_iter':[], 'catol':[], 'c':[], 'loss':[],\n",
    "                         'train_accuracy':[], 'test_accuracy':[], 'p_rule_train':[],\n",
    "                             'p_rule_test':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tamil-istanbul",
   "metadata": {},
   "outputs": [],
   "source": [
    "for alpha in alpha_list:\n",
    "    for max_iter in max_iter_list:\n",
    "        print(i)\n",
    "        with open('out'+ str(i) +'.log', 'w') as f:\n",
    "            with redirect_stdout(f):\n",
    "                c, loss, train_accuracy, test_accuracy, p_rule_train,\\\n",
    "                                                p_rule_test = train_test_classifier()\n",
    "                result['l'].append(l)\n",
    "                result['alpha'].append(alpha)\n",
    "                result['max_iter'].append(max_iter)\n",
    "                result['initiator'].append(initiator)\n",
    "                result['catol'].append(catol)\n",
    "                result['c'].append(c)\n",
    "                result['loss'].append(loss)\n",
    "                result['train_accuracy'].append(train_accuracy)\n",
    "                result['test_accuracy'].append(test_accuracy)\n",
    "                result['p_rule_train'].append(p_rule_train)\n",
    "                result['p_rule_test'].append(p_rule_test)\n",
    "        i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "following-forth",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result['train_accuracy'])\n",
    "print(result['test_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annoying-regard",
   "metadata": {},
   "outputs": [],
   "source": [
    "c, loss, train_accuracy, test_accuracy, p_rule_train,\\\n",
    "                                                p_rule_test = train_test_classifier()\n",
    "print(\"train accuracy: \", train_acuracy)\n",
    "print(\"test accuracy: \", test_acuracy)\n",
    "print(\"c : \", c)\n",
    "print(\"final loss: \", loss)\n",
    "print(\"p rule train : \", p_rule_train)\n",
    "print(\"p rule test: \", p_rule_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
